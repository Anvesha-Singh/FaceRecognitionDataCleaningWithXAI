{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition model with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "from rnn import FaceRecognitionRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class\n",
    "class LFWDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "lfw_path = r'C:\\Users\\Anvesha\\Documents\\Assignments\\AWS\\Implementation\\lfw_data\\aug'\n",
    "input_size = 4096  # Adjusted for 64x64 grayscale image flattened\n",
    "\n",
    "# Loading function\n",
    "def load_lfw_data():\n",
    "    X, y = [], []\n",
    "    for person_dir in os.listdir(lfw_path):\n",
    "        person_path = os.path.join(lfw_path, person_dir)\n",
    "        for image_file in os.listdir(person_path):\n",
    "            if image_file.endswith('.jpg'):\n",
    "                image_path = os.path.join(person_path, image_file)\n",
    "                image = Image.open(image_path).convert('L').resize((64, 64))\n",
    "                X.append(np.array(image).flatten())\n",
    "                y.append(person_dir)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Load the data\n",
    "X, y = load_lfw_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_k_fold_cross_validation(X, y, model_class, num_epochs=10, batch_size=32, lr=0.001, k=5):\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    best_model_path = 'cross_validation.pth'  # Path to save the best model\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "        print(f'Fold {fold + 1}/{k}')\n",
    "        \n",
    "        # Create train and validation datasets\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        \n",
    "        # Convert to PyTorch tensors and create DataLoader\n",
    "        train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "        val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # Initialize model, criterion, and optimizer\n",
    "        model = model_class(input_size=128, hidden_size=64, num_layers=2, num_classes=len(np.unique(y_train)))  # Update as needed\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        # Learning rate scheduler\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.1, verbose=True)\n",
    "\n",
    "        # Variable to track the best validation loss\n",
    "        best_val_loss = float('inf')\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in val_loader:\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            val_accuracy = correct / total\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs} - Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "            # Save the model if the current validation loss is the best\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                torch.save(model.state_dict(), best_model_path)  # Save model state dict\n",
    "                print(f'Saved the best model for fold {fold + 1} at epoch {epoch + 1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch 1/1 - Validation Loss: 8.3160, Validation Accuracy: 0.0005\n",
      "Saved the best model for fold 1 at epoch 1\n",
      "Fold 2/5\n",
      "Epoch 1/1 - Validation Loss: 8.3069, Validation Accuracy: 0.0002\n",
      "Saved the best model for fold 2 at epoch 1\n",
      "Fold 3/5\n",
      "Epoch 1/1 - Validation Loss: 8.3078, Validation Accuracy: 0.0007\n",
      "Saved the best model for fold 3 at epoch 1\n",
      "Fold 4/5\n",
      "Epoch 1/1 - Validation Loss: 8.3227, Validation Accuracy: 0.0002\n",
      "Saved the best model for fold 4 at epoch 1\n",
      "Fold 5/5\n",
      "Epoch 1/1 - Validation Loss: 8.2863, Validation Accuracy: 0.0000\n",
      "Saved the best model for fold 5 at epoch 1\n"
     ]
    }
   ],
   "source": [
    "stratified_k_fold_cross_validation(X, y_encoded, FaceRecognitionRNN, num_epochs=1, batch_size=32, lr=0.001, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation with Explainable AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will have to implement the xai part in each fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Model-agnostic Explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "class ModelWrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        X = torch.FloatTensor(X)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(X)\n",
    "            probas = torch.softmax(outputs, dim=1)\n",
    "        return probas.numpy()\n",
    "\n",
    "def analyze_interpretability(model, X, feature_names=None, \n",
    "                           use_sample=True, n_background=100, \n",
    "                           n_test_samples=5,\n",
    "                           lime_samples=1):\n",
    "    \n",
    "    print(\"Starting interpretability analysis...\")\n",
    "    \n",
    "    # Initialize feature names if not provided\n",
    "    if feature_names is None:\n",
    "        feature_names = [f\"feature_{i}\" for i in range(X.shape[1])]\n",
    "    \n",
    "    # Prepare data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Wrap model\n",
    "    model_wrapper = ModelWrapper(model)\n",
    "    \n",
    "    # SHAP Analysis\n",
    "    print(\"\\nPerforming SHAP analysis...\")\n",
    "    if use_sample:\n",
    "        print(f\"Using {n_background} background samples...\")\n",
    "        background_data = shap.kmeans(X_scaled, n_background)\n",
    "    else:\n",
    "        print(\"Using full dataset as background...\")\n",
    "        background_data = X_scaled\n",
    "    \n",
    "    explainer = shap.KernelExplainer(model_wrapper.predict_proba, background_data)\n",
    "    \n",
    "    # Calculate SHAP values\n",
    "    test_samples = X_scaled[:n_test_samples]\n",
    "    shap_values = explainer.shap_values(test_samples)\n",
    "    \n",
    "    # LIME Analysis\n",
    "    print(\"\\nPerforming LIME analysis...\")\n",
    "    lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "        X_scaled,\n",
    "        feature_names=feature_names,\n",
    "        class_names=[f\"Class_{i}\" for i in range(model.fc.out_features)],\n",
    "        mode=\"classification\"\n",
    "    )\n",
    "    \n",
    "    lime_explanations = []\n",
    "    for i in range(lime_samples):\n",
    "        print(f\"Generating LIME explanation for sample {i+1}/{lime_samples}\")\n",
    "        exp = lime_explainer.explain_instance(\n",
    "            X_scaled[i],\n",
    "            model_wrapper.predict_proba,\n",
    "            num_features=10\n",
    "        )\n",
    "        lime_explanations.append(exp)\n",
    "    \n",
    "    results = {\n",
    "        'shap_values': shap_values,\n",
    "        'shap_test_samples': test_samples,\n",
    "        'lime_explanations': lime_explanations,\n",
    "        'feature_names': feature_names,\n",
    "        'background_size': background_data.shape[0]\n",
    "    }\n",
    "    \n",
    "    print(\"\\nAnalysis completed!\")\n",
    "    print(f\"SHAP values shape: {[sv.shape for sv in shap_values]}\")\n",
    "    print(f\"Number of LIME explanations: {len(lime_explanations)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def analyze_both_datasets(model, X_original, X_cleaned, feature_names=None, \n",
    "                         use_sample=True, n_background=100, \n",
    "                         n_test_samples=5, lime_samples=1):\n",
    "    print(\"Starting comparative analysis...\")\n",
    "    \n",
    "    # Analyze original data\n",
    "    print(\"\\n=== Analyzing Original Data ===\")\n",
    "    original_results = analyze_interpretability(\n",
    "        model=model,\n",
    "        X=X_original,\n",
    "        feature_names=feature_names,\n",
    "        use_sample=use_sample,\n",
    "        n_background=n_background,\n",
    "        n_test_samples=n_test_samples,\n",
    "        lime_samples=lime_samples\n",
    "    )\n",
    "    \n",
    "    # Analyze cleaned data\n",
    "    print(\"\\n=== Analyzing Cleaned Data ===\")\n",
    "    cleaned_results = analyze_interpretability(\n",
    "        model=model,\n",
    "        X=X_cleaned,\n",
    "        feature_names=feature_names,\n",
    "        use_sample=use_sample,\n",
    "        n_background=n_background,\n",
    "        n_test_samples=n_test_samples,\n",
    "        lime_samples=lime_samples\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'original': original_results,\n",
    "        'cleaned': cleaned_results\n",
    "    }\n",
    "\n",
    "def plot_interpretability_results(results):\n",
    "    \"\"\"\n",
    "    Plot SHAP and LIME results\n",
    "    \"\"\"\n",
    "    # Plot SHAP summary\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.summary_plot(\n",
    "        results['shap_values'], \n",
    "        results['shap_test_samples'],\n",
    "        feature_names=results['feature_names'],\n",
    "        show=False\n",
    "    )\n",
    "    plt.title(\"SHAP Feature Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot LIME explanations\n",
    "    for i, exp in enumerate(results['lime_explanations']):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        exp.as_pyplot_figure()\n",
    "        plt.title(f\"LIME Explanation for Instance {i+1}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then run the analysis\n",
    "results = analyze_both_datasets(\n",
    "    model = FaceRecognitionRNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes),\n",
    "    X_original=X_train,\n",
    "    X_cleaned=X_train_cleaned,\n",
    "    use_sample=True,\n",
    "    n_background=10,\n",
    "    n_test_samples=5,\n",
    "    lime_samples=1\n",
    ")\n",
    "\n",
    "# # For full dataset analysis:\n",
    "# results = analyze_both_datasets(\n",
    "#     model = FaceRecognitionRNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes),\n",
    "#     X_original=X_train,\n",
    "#     X_cleaned=X_train_cleaned,\n",
    "#     use_sample=False,\n",
    "#     n_test_samples=20,\n",
    "#     lime_samples=5\n",
    "# )\n",
    "\n",
    "# Plot results for both datasets\n",
    "print(\"\\nPlotting Original Data Results:\")\n",
    "plot_interpretability_results(results['original'])\n",
    "\n",
    "print(\"\\nPlotting Cleaned Data Results:\")\n",
    "plot_interpretability_results(results['cleaned'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S-RISE (Saliency-guided Random Input Sampling for Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRISE:\n",
    "    def __init__(self, model, input_size, n_samples=1000, s=8, p1=0.5, sigma=2.0):\n",
    "        \"\"\"\n",
    "        Initialize S-RISE.\n",
    "        \n",
    "        Args:\n",
    "            model: The model to explain\n",
    "            input_size: Size of input features\n",
    "            n_samples: Number of mask samples\n",
    "            s: Stride size\n",
    "            p1: Base probability\n",
    "            sigma: Gaussian smoothing parameter\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        # Convert input_size to 2D if it's 1D\n",
    "        if isinstance(input_size, int):\n",
    "            self.height = int(np.sqrt(input_size))\n",
    "            self.width = self.height\n",
    "            if self.height * self.width != input_size:\n",
    "                raise ValueError(f\"Input size {input_size} must be a perfect square for 2D reshaping\")\n",
    "        else:\n",
    "            self.height, self.width = input_size\n",
    "            \n",
    "        self.n_samples = n_samples\n",
    "        self.s = s\n",
    "        self.p1 = p1\n",
    "        self.sigma = sigma\n",
    "        self.device = next(model.parameters()).device\n",
    "        self.masks = self.generate_masks()\n",
    "        \n",
    "    def gaussian_kernel(self, sigma):\n",
    "        \"\"\"Generate Gaussian kernel.\"\"\"\n",
    "        kernel_size = int(4 * sigma + 1)\n",
    "        if kernel_size % 2 == 0:\n",
    "            kernel_size += 1\n",
    "            \n",
    "        center = kernel_size // 2\n",
    "        x, y = np.meshgrid(np.arange(kernel_size), np.arange(kernel_size))\n",
    "        kernel = np.exp(-((x - center) ** 2 + (y - center) ** 2) / (2 * sigma ** 2))\n",
    "        kernel = kernel / kernel.sum()\n",
    "        \n",
    "        return torch.FloatTensor(kernel).unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    def gaussian_blur(self, x, sigma):\n",
    "        \"\"\"Apply Gaussian blur to tensor.\"\"\"\n",
    "        kernel = self.gaussian_kernel(sigma)\n",
    "        kernel = kernel.to(x.device)\n",
    "        channels = x.shape[1]\n",
    "        \n",
    "        # Ensure kernel size is smaller than input dimensions\n",
    "        if kernel.shape[-1] >= min(x.shape[-2:]):\n",
    "            kernel = self.gaussian_kernel(sigma/2)  # Use smaller kernel\n",
    "            \n",
    "        padding = kernel.shape[-1]//2\n",
    "        x_padded = torch.nn.functional.pad(x, (padding, padding, padding, padding), mode='reflect')\n",
    "        return torch.nn.functional.conv2d(x_padded, kernel, groups=channels)\n",
    "    \n",
    "    def generate_masks(self):\n",
    "        \"\"\"Generate random masks.\"\"\"\n",
    "        masks = []\n",
    "        for _ in range(self.n_samples):\n",
    "            # Generate 2D mask\n",
    "            h = int(np.ceil(self.height/self.s))\n",
    "            w = int(np.ceil(self.width/self.s))\n",
    "            mask = np.random.choice([0, 1], size=(h, w), p=[1-self.p1, self.p1])\n",
    "            \n",
    "            # Upsample to full size\n",
    "            mask = torch.FloatTensor(mask)\n",
    "            mask = nn.functional.interpolate(\n",
    "                mask.unsqueeze(0).unsqueeze(0),\n",
    "                size=(self.height, self.width),\n",
    "                mode='nearest'\n",
    "            )\n",
    "            \n",
    "            # Apply Gaussian smoothing\n",
    "            mask = self.gaussian_blur(mask, self.sigma).squeeze()\n",
    "            masks.append(mask)\n",
    "            \n",
    "        return torch.stack(masks).to(self.device)\n",
    "    \n",
    "    def explain(self, x, batch_size=32):\n",
    "        \"\"\"Generate saliency map for input x.\"\"\"\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.from_numpy(x)\n",
    "\n",
    "        # Convert the tensor to float32\n",
    "        x = x.float() \n",
    "\n",
    "        if len(x.shape) == 1:\n",
    "            # Reshape 1D input to 2D\n",
    "            x = x.unsqueeze(0).unsqueeze(0).view(1, 1, self.height, self.width)\n",
    "        elif len(x.shape) == 2:\n",
    "            # If it's already 2D, add the batch and channel dimensions\n",
    "            x = x.unsqueeze(0).unsqueeze(0)  # Shape becomes (1, 1, height, width)\n",
    "        elif len(x.shape) == 3:\n",
    "            # If it's 3D, assume the input shape is (channels, height, width)\n",
    "            x = x.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Get original prediction\n",
    "            original_pred = self.model(x)\n",
    "            pred_class = original_pred.argmax().item()\n",
    "            \n",
    "            # Process masks in batches\n",
    "            for i in range(0, self.n_samples, batch_size):\n",
    "                batch_masks = self.masks[i:i+batch_size]\n",
    "                batch_size = len(batch_masks)\n",
    "                \n",
    "                # Apply masks\n",
    "                masked_inputs = x.repeat(batch_size, 1, 1, 1) * batch_masks.unsqueeze(1)\n",
    "                batch_preds = self.model(masked_inputs.view(batch_size, -1))\n",
    "                predictions.append(batch_preds[:, pred_class])\n",
    "                \n",
    "        # Calculate saliency map\n",
    "        predictions = torch.cat(predictions)\n",
    "        saliency_map = torch.zeros(self.height * self.width, dtype=torch.float32)\n",
    "        \n",
    "        for i, pred in enumerate(predictions):\n",
    "            saliency_map += pred * self.masks[i].view(-1)\n",
    "            \n",
    "        return saliency_map.view(self.height, self.width)\n",
    "    \n",
    "    def visualize(self, x, saliency_map, save_path):\n",
    "        \"\"\"Visualize original input and saliency map.\"\"\"\n",
    "        plt.figure(figsize=(10, 5))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title('Original Input')\n",
    "        \n",
    "        # Check if x is a tensor and print its shape\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            # Ensure x is reshaped and moved to CPU before converting to NumPy\n",
    "            if len(x.shape) == 1:\n",
    "                x = x.view(1, -1)  # Ensure it's at least 2D\n",
    "            original_input = x.view(self.height, self.width).cpu().detach().numpy()\n",
    "        else:\n",
    "            raise ValueError(\"Input x must be a torch.Tensor\")\n",
    "        \n",
    "        plt.imshow(original_input, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Plot saliency map\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title('Saliency Map')\n",
    "        \n",
    "        # Ensure saliency_map is moved to CPU before converting to NumPy\n",
    "        if isinstance(saliency_map, torch.Tensor):\n",
    "            saliency_map_cpu = saliency_map.cpu().detach().numpy()\n",
    "        else:\n",
    "            raise ValueError(\"Saliency map must be a torch.Tensor\")\n",
    "\n",
    "        plt.imshow(saliency_map_cpu, cmap='hot')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.savefig(save_path)\n",
    "        plt.show()\n",
    "\n",
    "def compare_srise_explanations(model, X_original, X_cleaned, n_samples=3):\n",
    "    \"\"\"Compare SRISE explanations for original and cleaned data.\"\"\"\n",
    "    input_size = X_original.shape[1]\n",
    "    srise = SRISE(model, input_size)\n",
    "    \n",
    "    plt.figure(figsize=(12, 4*n_samples))\n",
    "    for i in range(n_samples):\n",
    "        # Original data\n",
    "        smap_original = srise.explain(X_original[i])\n",
    "        plt.subplot(n_samples, 2, 2*i + 1)\n",
    "        plt.title(f'Original Data - Sample {i+1}')\n",
    "        plt.imshow(smap_original.cpu().numpy(), cmap='hot')\n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Cleaned data\n",
    "        smap_cleaned = srise.explain(X_cleaned[i])\n",
    "        plt.subplot(n_samples, 2, 2*i + 2)\n",
    "        plt.title(f'Cleaned Data - Sample {i+1}')\n",
    "        plt.imshow(smap_cleaned.cpu().numpy(), cmap='hot')\n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize S-RISE with your model\n",
    "srise = SRISE(\n",
    "    model = FaceRecognitionRNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes),\n",
    "    input_size=4096,  # Will be automatically reshaped to (64, 64)\n",
    "    n_samples=1000,\n",
    "    s=8,\n",
    "    p1=0.5,\n",
    "    sigma=2.0\n",
    ")\n",
    "\n",
    "# Generate saliency map for a sample\n",
    "sample = X_train[0]\n",
    "\n",
    "# Convert ndarray to PyTorch tensor\n",
    "if isinstance(sample, np.ndarray):\n",
    "    sample = torch.tensor(sample)\n",
    "\n",
    "# Ensure the tensor is of type float32\n",
    "sample = sample.float()\n",
    "    \n",
    "saliency_map = srise.explain(sample, batch_size=32)\n",
    "\n",
    "# Visualize results\n",
    "srise.visualize(sample, saliency_map, save_path='srise_visualization.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original and cleaned data\n",
    "def compare_srise_explanations(model, X_original, X_cleaned, n_samples=3):\n",
    "    srise = SRISE(model, X_original.shape[1])\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Original data\n",
    "        original = X_original[i]\n",
    "        smap_original = srise.explain(original)\n",
    "        print(f\"\\nOriginal Data - Sample {i+1}:\")\n",
    "        if isinstance(original, np.ndarray):\n",
    "            original = torch.tensor(original)\n",
    "        original = original.float()\n",
    "        srise.visualize(original, smap_original, save_path='srise_visualization_original.png')\n",
    "        \n",
    "        # Cleaned data\n",
    "        cleaned =  X_cleaned[i]\n",
    "        smap_cleaned = srise.explain(cleaned)\n",
    "        print(f\"\\nCleaned Data - Sample {i+1}:\")\n",
    "        if isinstance(cleaned, np.ndarray):\n",
    "            cleaned = torch.tensor(cleaned)\n",
    "        cleaned = cleaned.float()\n",
    "        srise.visualize(cleaned, smap_cleaned, save_path='srise_visualization_cleaned.png')\n",
    "        \n",
    "# Run comparison\n",
    "compare_srise_explanations(\n",
    "    model = FaceRecognitionRNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes),\n",
    "    X_original=X_train,\n",
    "    X_cleaned=X_train_cleaned,\n",
    "    n_samples=3\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
